version: '2.1'
services:
    redis:
        image: 'redis:5.0.5'
        # command: redis-server --requirepass redispass

    postgres:
        image: postgres:latest
        environment:
            - POSTGRES_USER=$POSTGRES_AIRFLOW_USER
            - POSTGRES_PASSWORD=$POSTGRES_AIRFLOW_PASSWORD
            - POSTGRES_DB=$POSTGRES_AIRFLOW_DB
        # Uncomment these lines to persist data on the local filesystem.
        #     - PGDATA=/var/lib/postgresql/data/pgdata
        # volumes:
        #     - ./pgdata:/var/lib/postgresql/data/pgdata

    webserver:
        image: datafuel/airflow:latest
        restart: always
        depends_on:
            - postgres
            - redis
        environment:
            - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql://${POSTGRES_AIRFLOW_USER}:${POSTGRES_AIRFLOW_PASSWORD}@postgres:5432/${POSTGRES_AIRFLOW_DB}
            - AIRFLOW_ADMIN_USERNAME=$AIRFLOW_ADMIN_USERNAME
            - AIRFLOW_ADMIN_PASSWORD=$AIRFLOW_ADMIN_PASSWORD
            - AIRFLOW_ADMIN_FIRST_NAME=$AIRFLOW_ADMIN_FIRST_NAME
            - AIRFLOW_ADMIN_LAST_NAME=$AIRFLOW_ADMIN_LAST_NAME
            - AIRFLOW_ADMIN_EMAIL=$AIRFLOW_ADMIN_EMAIL
            # - POSTGRES_USER=airflow
            # - POSTGRES_PASSWORD=airflow
            # - POSTGRES_DB=airflow
            # - REDIS_PASSWORD=redispass
        volumes:
            - ./dags:/usr/local/airflow/dags
            - ./airflow_dir/setup/airflow.cfg:${AIRFLOW_USER_HOME}/airflow.cfg
            - ./airflow_dir/setup/setup.sh:${AIRFLOW_USER_HOME}/setup.sh
            # Uncomment to include custom plugins
            # - ./plugins:/usr/local/airflow/plugins
        ports:
            - "8080:8080"
        stdin_open: true
        tty: true
        command: /bin/bash setup.sh
        # healthcheck:
        #     test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
        #     interval: 30s
        #     timeout: 30s
        #     retries: 3

    flower:
        image: datafuel/airflow:latest
        restart: always
        depends_on:
            - redis
        environment:
            - EXECUTOR=Celery
            - AIRFLOW__CELERY__RESULT_BACKEND_SECRET=postgresql://${POSTGRES_AIRFLOW_USER}:${POSTGRES_AIRFLOW_PASSWORD}@postgres:5432/${POSTGRES_AIRFLOW_DB}
            - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql://${POSTGRES_AIRFLOW_USER}:${POSTGRES_AIRFLOW_PASSWORD}@postgres:5432/${POSTGRES_AIRFLOW_DB}
            # - REDIS_PASSWORD=redispass
        volumes:
            - ./airflow_dir/setup/airflow.cfg:${AIRFLOW_USER_HOME}/airflow.cfg
        ports:
            - "5555:5555"
        command: airflow celery flower

    scheduler:
        image: datafuel/airflow:latest
        restart: always
        depends_on:
            - webserver
        volumes:
            - ./dags:/usr/local/airflow/dags
            - ./airflow_dir/setup/airflow.cfg/:${AIRFLOW_USER_HOME}/airflow.cfg
            # - ./airflow_dir/airflow.cfg/:${AIRFLOW_USER_HOME}/airflow.cfg
            # - ./airflow_dir/entrypoint.sh:${AIRFLOW_USER_HOME}/entrypoint.sh
            # Uncomment to include custom plugins
            # - ./plugins:/usr/local/airflow/plugins
        environment:
            - LOAD_EX=n
            - EXECUTOR=Celery
            - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql://${POSTGRES_AIRFLOW_USER}:${POSTGRES_AIRFLOW_PASSWORD}@postgres:5432/${POSTGRES_AIRFLOW_DB}
            # - POSTGRES_USER=airflow
            # - POSTGRES_PASSWORD=airflow
            # - POSTGRES_DB=airflow
            # - REDIS_PASSWORD=redispass
        command: airflow scheduler

    worker:
        image: datafuel/airflow:latest
        restart: always
        depends_on:
            - scheduler
        volumes:
            - ./dags:/usr/local/airflow/dags
            - ./airflow_dir/setup/airflow.cfg:${AIRFLOW_USER_HOME}/airflow.cfg
            # - ./airflow_dir/airflow.cfg/:${AIRFLOW_USER_HOME}/airflow.cfg
            # - ./airflow_dir/entrypoint.sh:${AIRFLOW_USER_HOME}/entrypoint.sh
            # Uncomment to include custom plugins
            # - ./plugins:/usr/local/airflow/plugins
        environment:
            - EXECUTOR=Celery
            - AIRFLOW__CELERY__RESULT_BACKEND_SECRET=postgresql://${POSTGRES_AIRFLOW_USER}:${POSTGRES_AIRFLOW_PASSWORD}@postgres:5432/${POSTGRES_AIRFLOW_DB}
            - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql://${POSTGRES_AIRFLOW_USER}:${POSTGRES_AIRFLOW_PASSWORD}@postgres:5432/${POSTGRES_AIRFLOW_DB}            # - POSTGRES_USER=airflow
            # - POSTGRES_PASSWORD=airflow
            # - POSTGRES_DB=airflow
            # - REDIS_PASSWORD=redispass
        command: airflow celery worker
    
    minio:
        hostname: minio
        image: minio/minio
        container_name: minio
        ports:
            - '9000:9000'
        volumes:
            - './minio/data/:/data'
            - './minio/config:/root/.minio'
        environment:
            MINIO_ACCESS_KEY: $MINIO_ACCESS_KEY
            MINIO_SECRET_KEY: $MINIO_SECRET_KEY
        command: server /data
                
    presto-coordinator:
        image: lewuathe/presto-coordinator:309
        ports:
            - "8081:8080"
        container_name: "coordinator"
        command: coordinator
        volumes:
            - ./presto_dir/etc/coordinator/etc:/usr/local/presto-server-309/etc
            # - ./minio/data/:/minio/data
            # - hive-temporary-staging-directory:/mnt/presto/data/tmp
        environment:
            MINIO_ACCESS_KEY: $MINIO_ACCESS_KEY
            MINIO_SECRET_KEY: $MINIO_SECRET_KEY
    
    presto-worker0:
        image: lewuathe/presto-worker:309
        container_name: "worker0"
        ports:
            - "8082:8081"
        command: worker0
        volumes:
            - ./presto_dir/etc/worker/etc:/usr/local/presto-server-309/etc
            # - ./minio/data/:/minio/data
            # - hive-temporary-staging-directory:/mnt/presto/data/tmp
        environment:
            MINIO_ACCESS_KEY: $MINIO_ACCESS_KEY
            MINIO_SECRET_KEY: $MINIO_SECRET_KEY

    # Hive

    hive-server:
        image: johannestang/hive:2.3.6-postgresql-metastore-s3
        restart: always
        environment:
            HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
            SERVICE_PRECONDITION: "hive-metastore:9083"
            HDFS_CONF_fs_s3a_access_key: ${MINIO_ACCESS_KEY}
            HDFS_CONF_fs_s3a_secret_key: ${MINIO_SECRET_KEY}
        ports:
            - "10000:10000"
            - "10002:10002"


    hive-metastore:
        image: johannestang/hive:2.3.6-postgresql-metastore-s3
        restart: always
        command: /opt/hive/bin/hive --service metastore
        environment:
            SERVICE_PRECONDITION: "hive-metastore-postgresql:5432"
            HDFS_CONF_fs_s3a_access_key: ${MINIO_ACCESS_KEY}
            HDFS_CONF_fs_s3a_secret_key: ${MINIO_SECRET_KEY}
        ports:
            - "9083:9083"
        

    hive-metastore-postgresql:
        image: bde2020/hive-metastore-postgresql:2.3.0
networks: 
    default: 
        external: 
            name: datafuel-local-network
            